{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux Auditd\n",
    "\n",
    "|         |            |\n",
    "|---|:-------------|\n",
    "| Version     | 0.1 |\n",
    "| Author      | {author}      |\n",
    "| Contact | {email}      |\n",
    "| Data tables used | {tablelist here...                                                      }|\n",
    "\n",
    "## Description:\n",
    "{the description}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "## Contents\n",
    "- [Setup and Authenticate](#setup)\n",
    "\n",
    "- [First Section](#sectionone)\n",
    "- [More Sections](#moresections)\n",
    "- [Appendices](#appendices)\n",
    "  - [Saving data to Excel](#appendices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>[Contents](#toc)\n",
    "# Setup\n",
    "\n",
    "If you are running this from an Azure Notebooks instance created by ASI you can ignore the *Install Packages* step.\n",
    "\n",
    "\n",
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may needs these - should only need to uncomment and run once\n",
    "# !pip install msgpack\n",
    "# !pip install Kqlmagic --no-cache-dir  --upgrade\n",
    "\n",
    "# !pip install PyHamcrest\n",
    "# !conda install -c conda-forge python-levenshtein -y\n",
    "# !conda install requests\n",
    "# !conda install attrs\n",
    "# !conda install seaborn\n",
    "# !conda install bokeh\n",
    "# !conda install holoviews\n",
    "\n",
    "# our package\n",
    "#!pip install ../python --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "MIN_REQ_PYTHON = (3,6)\n",
    "if sys.version_info < MIN_REQ_PYTHON:\n",
    "    print('Check the Kernel->Change Kernel menu and ensure that Python 3.6')\n",
    "    print('or later is selected as the active kernel.')\n",
    "    sys.exit(\"Python %s.%s or later is required.\\n\" % MIN_REQ_PYTHON)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "sns.set()\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "   \n",
    "import msticpy.sectools as sectools\n",
    "import msticpy.asitools as asi\n",
    "import msticpy.asitools.kql as qry\n",
    "import msticpy.asitools.nbdisplay as asidisp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "source": [
    "### Enter or confirm WorkspaceId\n",
    "To find your Workspace Id go to [Log Analytics](#https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_workspaces = {'Contoso77':'802d39e1-9d70-404d-832c-2de5e2478eda', \n",
    "                        'MSTICLinux':'06dc719f-5dad-47e9-b5af-07d84a0bda4e',\n",
    "                        'ASIHuntOMSWorkspaceV4': '52b1ab41-869e-4138-9e40-2a4457f09bf0',\n",
    "                        'ASIHuntOMSWorkspaceV5': '4ca7b24a-6e8f-4540-a8ce-1a80c2948c37',\n",
    "                        'Rome ILDC - Detection E2E Tests Stage': '3eb61071-5dcd-4db3-94fa-0091a69b7359'}\n",
    "select_ws = asi.SelectString(description='Select workspace :',\n",
    "                             item_dict=available_workspaces)\n",
    "\n",
    "select_ws.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from msticpy.asitools.asiconfig import WorkspaceConfig\n",
    "ws_config_file = 'config.json'\n",
    "try:\n",
    "    ws_config = WorkspaceConfig(ws_config_file)\n",
    "    print('Found config file')\n",
    "    for cf_item in ['tenant_id', 'subscription_id', 'resource_group', 'workspace_id', 'workspace_name']:\n",
    "        print(cf_item, ws_config[cf_item])\n",
    "except:\n",
    "    ws_config = None\n",
    "\n",
    "ws_id = asi.GetEnvironmentKey(env_var='WORKSPACE_ID',\n",
    "                              prompt='Log Analytics Workspace Id:')\n",
    "if ws_config:\n",
    "    ws_id.value = ws_config['workspace_id']\n",
    "ws_id.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate to Log Analytics\n",
    "If you are using user/device authentication, run the following cell. \n",
    "- Click the 'Copy code to clipboard and authenticate' button.\n",
    "- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n",
    "- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n",
    "- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n",
    "\n",
    "Use the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n",
    "```\n",
    "%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n",
    "```\n",
    "instead of\n",
    "```\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    WORKSPACE_ID = select_ws.value\n",
    "except NameError:\n",
    "    try:\n",
    "        WORKSPACE_ID = ws_id.value\n",
    "    except NameError:\n",
    "        WORKSPACE_ID = None\n",
    "    \n",
    "if not WORKSPACE_ID:\n",
    "    raise ValueError('No workspace selected.')\n",
    "\n",
    "asi.kql.load_kql_magic()\n",
    "\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "todo"
    ]
   },
   "source": [
    "<a id='sectionone'></a>[Contents](#toc)\n",
    "# Section One\n",
    "\n",
    "Specify a time range to search for X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_times = asi.QueryTime(units='day', max_before=20, before=5, max_after=1)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linux Events from Auditd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux test\n",
    "linux_events = r'''\n",
    "AuditLog_CL\n",
    "| where Computer startswith 'MSTIC'\n",
    "| where TimeGenerated > ago(1h)\n",
    "| extend mssg_parts = extract_all(@\"type=(?P<type>[^\\s]+)\\s+msg=audit\\((?P<mssg_id>[^)]+)\\):\\s+(?P<mssg>[^\\r]+)\\r?\", dynamic(['type', 'mssg_id', 'mssg']), RawData)\n",
    "| extend mssg_type = tostring(mssg_parts[0][0]), mssg_id = tostring(mssg_parts[0][1])\n",
    "| project TenantId, TimeGenerated, Computer, mssg_type, mssg_id, mssg_parts\n",
    "| extend mssg_content = split(mssg_parts[0][2],' ')\n",
    "| extend typed_mssg = pack(mssg_type, mssg_content)\n",
    "| summarize AuditdMessage = makelist(typed_mssg) by TenantId, TimeGenerated, Computer, mssg_id'''\n",
    "%kql -query linux_events\n",
    "linux_events_df = _kql_raw_result_.to_dataframe()\n",
    "len(linux_events_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with data that looks like this in the AuditMessage column:\n",
    "```\n",
    "[{'SYSCALL': ['arch=c000003e',\n",
    "   'syscall=59',\n",
    "   'success=yes',\n",
    "   'exit=0',\n",
    "   'a0=7f36addfbc18',\n",
    "   'a1=7f36a934a3f0',\n",
    "   'a2=7ffd0f830c50',\n",
    "   'a3=9',\n",
    "   'items=2',\n",
    "   'ppid=25281',\n",
    "   'pid=534',\n",
    "   'auid=4294967295',\n",
    "   'uid=0',\n",
    "   'gid=0',\n",
    "   'euid=0',\n",
    "   'suid=0',\n",
    "   'fsuid=0',\n",
    "   'egid=0',\n",
    "   'sgid=0',\n",
    "   'fsgid=0',\n",
    "   'tty=(none)',\n",
    "   'ses=4294967295',\n",
    "   'comm=\"sh\"',\n",
    "   'exe=\"/bin/dash\"',\n",
    "   'key=(null)']},\n",
    " {'EXECVE': ['argc=3',\n",
    "   'a0=\"/bin/sh\"',\n",
    "   'a1=\"-c\"',\n",
    "   'a2=69707461626C6573202D2D76657273696F6E']},\n",
    " {'CWD': ['cwd=\"/var/lib/waagent/WALinuxAgent-2.2.35.1\"']},\n",
    " {'PATH': ['item=0',\n",
    "   'name=\"/bin/sh\"',\n",
    "   'inode=26',\n",
    "   'dev=08:01',\n",
    "   'mode=0100755',\n",
    "   'ouid=0',\n",
    "   'ogid=0',\n",
    "   'rdev=00:00',\n",
    "   'nametype=NORMAL',\n",
    "   'cap_fp=0000000000000000',\n",
    "   'cap_fi=0000000000000000',\n",
    "   'cap_fe=0',\n",
    "   'cap_fver=0']},\n",
    " {'PATH': ['item=1',\n",
    "   'name=\"/lib64/ld-linux-x86-64.so.2\"',\n",
    "   'inode=2081',\n",
    "   'dev=08:01',\n",
    "   'mode=0100755',\n",
    "   'ouid=0',\n",
    "   'ogid=0',\n",
    "   'rdev=00:00',\n",
    "   'nametype=NORMAL',\n",
    "   'cap_fp=0000000000000000',\n",
    "   'cap_fi=0000000000000000',\n",
    "   'cap_fe=0',\n",
    "   'cap_fver=0']},\n",
    " {'PROCTITLE': ['proctitle=2F62696E2F7368002D630069707461626C6573202D2D76657273696F6E']}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from datetime import datetime\n",
    "\n",
    "encoded_params = {'EXECVE': {'a0', 'a1', 'a2', 'a3', 'arch'},\n",
    "                  'PROCTITLE': {'proctitle'},\n",
    "                  'USER_CMD': {'cmd'}}\n",
    "\n",
    "def unpack_auditd(audit_str):\n",
    "    event_dict = {}\n",
    "    for record in audit_str:\n",
    "        \n",
    "        for rec_key, rec_val in record.items():\n",
    "            rec_dict = {}\n",
    "            encoded_fields_map = encoded_params.get(rec_key, None)\n",
    "            for rec_item in rec_val:\n",
    "                rec_split = rec_item.split('=', maxsplit=1)\n",
    "                if (not encoded_fields_map or rec_split[1].startswith('\"') or\n",
    "                        rec_split[0] not in encoded_fields_map):\n",
    "                    field_value = rec_split[1].strip('\\\"')\n",
    "                else:\n",
    "                    try:\n",
    "                        field_value = codecs.decode(rec_split[1], 'hex').decode('utf-8')\n",
    "                    except:\n",
    "                        field_value = rec_split[1]\n",
    "                        print(rec_val)\n",
    "                        print('ERR:', rec_key, rec_split[0], rec_split[1], type(rec_split[1]))\n",
    "                rec_dict[rec_split[0]] = field_value\n",
    "            event_dict[rec_key] = rec_dict\n",
    "        \n",
    "    return event_dict\n",
    "\n",
    "USER_START = {'pid': 'int', 'uid': 'int', 'auid': 'int', \n",
    "              'ses': 'int', 'msg': None, 'acct': None, 'exe': None, \n",
    "              'hostname': None, 'addr': None, 'terminal': None, \n",
    "              'res': None}\n",
    "FIELD_DEFS = {'SYSCALL': {'success': None, 'ppid': 'int', 'pid': 'int', \n",
    "                          'auid': 'int', 'uid': 'int', 'gid': 'int',\n",
    "                          'euid': 'int', 'egid': 'int', 'ses': 'int',\n",
    "                          'exe': None, 'com': None},\n",
    "              'CWD': {'cwd': None},\n",
    "              'PROCTITLE': {'proctitle': None},\n",
    "              'LOGIN': {'pid': 'int', 'uid': 'int', 'tty': None, 'old-ses': 'int', \n",
    "                        'ses': 'int', 'res': None},\n",
    "              'EXECVE': {'argc': 'int', 'a0': None, 'a1': None, 'a2': None},\n",
    "              'USER_START': USER_START,\n",
    "              'USER_END': USER_START,\n",
    "              'CRED_DISP': USER_START,\n",
    "              'USER_ACCT': USER_START,\n",
    "              'CRED_ACQ': USER_START,\n",
    "              'USER_CMD': {'pid': 'int', 'uid': 'int', 'auid': 'int', \n",
    "                           'ses': 'int', 'msg': None, 'cmd': None,\n",
    "                           'terminal': None, 'res': None},\n",
    "             }\n",
    "\n",
    "def extract_event(message_dict):\n",
    "    if 'SYSCALL' in message_dict:\n",
    "        proc_create_dict = {}\n",
    "        for mssg_type in ['SYSCALL', 'CWD', 'EXECVE', 'PROCTITLE']:\n",
    "            if (not mssg_type in message_dict or\n",
    "                    not mssg_type in FIELD_DEFS) :\n",
    "                continue\n",
    "            for fieldname, conv in FIELD_DEFS[mssg_type].items():\n",
    "                value = message_dict[mssg_type].get(fieldname, None)\n",
    "                if not value:\n",
    "                    continue\n",
    "                if conv:\n",
    "                    if conv == 'int':\n",
    "                        value = int(value)\n",
    "                        if value == 4294967295:\n",
    "                            value = -1\n",
    "                proc_create_dict[fieldname] = value\n",
    "            if mssg_type == 'EXECVE':\n",
    "                args = int(proc_create_dict.get('argc', 1))\n",
    "                arg_strs = []\n",
    "                for arg_idx in range(0, args):\n",
    "                    arg_strs.append(proc_create_dict.get(f'a{arg_idx}', ''))\n",
    "                    \n",
    "                proc_create_dict['cmdline'] = ' '.join(arg_strs)\n",
    "        return 'SYSCALL', proc_create_dict\n",
    "    else:\n",
    "        event_dict = {}                                            \n",
    "        for mssg_type, mssg in message_dict.items():\n",
    "            if mssg_type in FIELD_DEFS:\n",
    "                for fieldname, conv in FIELD_DEFS[mssg_type].items():\n",
    "                    value = message_dict[mssg_type].get(fieldname, None)\n",
    "                    if conv:\n",
    "                        if conv == 'int':\n",
    "                            value = int(value)\n",
    "                            if value == 4294967295:\n",
    "                                value = -1\n",
    "                    event_dict[fieldname] = value\n",
    "            else:\n",
    "                event_dict.update(message_dict[mssg_type])\n",
    "        return list(message_dict.keys())[0], event_dict\n",
    "\n",
    "def move_cols_to_front(df, column_count):\n",
    "    \"\"\"Reorder columms to put the last column count cols to front.\"\"\"\n",
    "    return df[list(df.columns[-column_count:]) + list(df.columns[:-column_count])]\n",
    "\n",
    "\n",
    "def extract_events_to_df(data, event_type=None, verbose=False):\n",
    "    \n",
    "    if verbose:\n",
    "        start_time = datetime.utcnow()\n",
    "        print(f'Unpacking auditd messages for {len(data)} events...')\n",
    "    tmp_df = (data.apply(lambda x: extract_event(unpack_auditd(x.AuditdMessage)), \n",
    "                         axis=1, result_type='expand')\n",
    "                  .rename(columns={0: 'EventType', \n",
    "                                   1: 'EventData'})\n",
    "                  )\n",
    "    # if only one type of event is requested\n",
    "    if event_type:\n",
    "        tmp_df = tmp_df[tmp_df['EventType'] == event_type]\n",
    "        if verbose:\n",
    "            print(f'Event subset = ', event_type, ' (events: {len(tmp_df)})')\n",
    "    \n",
    "    if verbose:\n",
    "        print('Building output dataframe...')\n",
    "        \n",
    "    tmp_df = (tmp_df.apply(lambda x: pd.Series(x.EventData), axis=1)\n",
    "              .merge(tmp_df[['EventType']], left_index=True, right_index=True)\n",
    "              .merge(data.drop(['AuditdMessage'], axis=1), \n",
    "                 how='inner', left_index=True, right_index=True)\n",
    "              .dropna(axis=1, how='all'))\n",
    "    \n",
    "    if verbose:\n",
    "        print('Fixing timestamps...')\n",
    "        \n",
    "    # extract real timestamp from mssg_id\n",
    "    tmp_df['TimeStamp'] = (tmp_df.apply(lambda x:\n",
    "                                        datetime.utcfromtimestamp(float(x.mssg_id.split(':')[0])),\n",
    "                                        axis=1))\n",
    "    tmp_df = (tmp_df.drop(['TimeGenerated'], axis=1)\n",
    "                    .rename(columns={'TimeStamp': 'TimeGenerated'})\n",
    "                    .pipe(move_cols_to_front, column_count=5))\n",
    "    if verbose:\n",
    "        print(f'Complete. {len(tmp_df)} output rows', end=' ')\n",
    "        delta = datetime.utcnow() - start_time\n",
    "        print(f'time: {delta.seconds + delta.microseconds/1_000_000} sec')\n",
    "        \n",
    "    return tmp_df\n",
    "                   \n",
    "\n",
    "def get_event_subset(data, event_type):\n",
    "    return (data[data['EventType'] == event_type]\n",
    "             .dropna(axis=1, how='all')\n",
    "             .infer_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linux_events_all = extract_events_to_df(linux_events_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "(linux_events_all[['EventType', 'TimeGenerated']]\n",
    "     .groupby('EventType').count().rename(columns={'TimeGenerated': 'EventCount'})\n",
    "     .sort_values('EventCount', ascending=True)\n",
    "     .plot.barh(logx=True, figsize=(12,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Individual Event Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_proc_create = get_event_subset(linux_events_all,'SYSCALL')\n",
    "print(f'{len(proc_create)} Process Create Events')\n",
    "\n",
    "lx_login = (get_event_subset(linux_events_all, 'LOGIN')\n",
    "        .merge(get_event_subset(linux_events_all, 'CRED_ACQ'), \n",
    "               how='inner',\n",
    "               left_on=['old-ses', 'pid', 'uid'], \n",
    "               right_on=['ses', 'pid', 'uid'],\n",
    "               suffixes=('', '_cred')).drop(['old-ses','TenantId_cred', \n",
    "                                             'Computer_cred'], axis=1)\n",
    "        .dropna(axis=1, how='all'))\n",
    "print(f'{len(login)} Login Events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Event Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "known_type_mask = linux_events_all['EventType'].map(lambda x: x in list(FIELD_DEFS.keys()))\n",
    "other_events = (linux_events_all[known_type_mask == False])\n",
    "other_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Process Creation with Logons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_login.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Process with login data to get account details for processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_col_list = ['a0', 'a1', 'a2', 'argc', 'tty',\n",
    "                 'EventType_log', 'mssg_id_log',\n",
    "                 'TenantId_log', 'Computer_log',\n",
    "                 'TimeGenerated_cred', 'res_cred', 'ses_cred', 'msg']\n",
    "proc_create_log = lx_proc_create.merge(lx_login, \n",
    "                                    how='left',\n",
    "                                    left_on=['ses'], right_on=['ses'],\n",
    "                                    suffixes=('', '_log')).drop(drop_col_list, axis=1)\n",
    "\n",
    "len(proc_create_log)\n",
    "proc_create_log[pd.notna(proc_create_log['uid_log'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linuxLogins'></a>[Contents](#toc)\n",
    "# Linux Logins with IP Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_login[lx_login['addr'] != '?'][['Computer', 'TimeGenerated', \n",
    "                                   'pid', 'ses', 'acct', 'addr', \n",
    "                                   'exe', 'hostname', 'msg',\n",
    "                                   'res_cred', 'ses_cred', 'terminal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_create_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_to_proc_create = {'acct': 'SubjectUserName',\n",
    "                     'uid': 'SubjectUserSid',\n",
    "                     'user': 'SubjectUserName',\n",
    "                     'ses': 'SubjectLogonId',\n",
    "                     'pid': 'NewProcessId',\n",
    "                     'exe': 'NewProcessName',\n",
    "                     'ppid': 'ProcessId',\n",
    "                     'cmdline': 'CommandLine',}\n",
    "\n",
    "proc_create_to_lx = {'SubjectUserName': 'acct',\n",
    "                     'SubjectUserSid': 'uid',\n",
    "                     'SubjectUserName': 'user',\n",
    "                     'SubjectLogonId': 'ses',\n",
    "                     'NewProcessId': 'pid',\n",
    "                     'NewProcessName': 'exe',\n",
    "                     'ProcessId': 'ppid',\n",
    "                     'CommandLine': 'cmdline',}\n",
    "\n",
    "lx_to_logon = {'acct': 'SubjectUserName',\n",
    "               'auid': 'SubjectUserSid',\n",
    "               'user': 'TargetUserName',\n",
    "               'uid': 'TargetUserSid',\n",
    "               'ses': 'TargetLogonId',\n",
    "               'exe': 'LogonProcessName',\n",
    "               'terminal': 'LogonType',\n",
    "               'msg': 'AuthenticationPackageName',\n",
    "               'res': 'Status',\n",
    "               'addr': 'IpAddress',\n",
    "               'hostname': 'WorkstationName',}\n",
    "\n",
    "logon_to_lx = {'SubjectUserName': 'acct',\n",
    "               'SubjectUserSid': 'auid',\n",
    "               'TargetUserName': 'user',\n",
    "               'TargetUserSid': 'uid',\n",
    "               'TargetLogonId': 'ses',\n",
    "               'LogonProcessName': 'exe',\n",
    "               'LogonType': 'terminal',\n",
    "               'AuthenticationPackageName': 'msg',\n",
    "               'Status': 'res',\n",
    "               'IpAddress': 'addr',\n",
    "               'WorkstationName': 'hostname',}\n",
    "\n",
    "lx_proc_create_trans = lx_proc_create.rename(columns=lx_to_proc_create)\n",
    "lx_login_trans = lx_login.rename(columns=lx_to_logon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Distinct Processes in Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msticpy.sectools.eventcluster import dbcluster_events, add_process_features\n",
    "\n",
    "feature_procs_h1 = add_process_features(input_frame=lx_proc_create_trans,\n",
    "                                        path_separator='/')\n",
    "\n",
    "\n",
    "# you might need to play around with the max_cluster_distance parameter.\n",
    "# decreasing this gives more clusters.\n",
    "(clus_events, dbcluster, x_data) = dbcluster_events(data=feature_procs_h1,\n",
    "                                                    cluster_columns=['commandlineTokensFull', \n",
    "                                                                     'pathScore', \n",
    "                                                                     'isSystemSession',\n",
    "                                                                     'SubjectLogonId'],\n",
    "                                                    time_column='TimeGenerated',\n",
    "                                                    max_cluster_distance=0.0001)\n",
    "print('Number of input events:', len(feature_procs_h1))\n",
    "print('Number of clustered events:', len(clus_events))\n",
    "(clus_events.sort_values('TimeGenerated')[['TimeGenerated', 'LastEventTime',\n",
    "                                           'NewProcessName', 'CommandLine', \n",
    "                                           'ClusterSize', 'commandlineTokensFull',\n",
    "                                           'SubjectLogonId',\n",
    "                                           'pathScore', 'isSystemSession']]\n",
    "    .sort_values('ClusterSize', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='appendices'></a>[Contents](#toc)\n",
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('List of current DataFrames in Notebook')\n",
    "print('-' * 50)\n",
    "current_vars = list(locals().keys())\n",
    "for var_name in current_vars:\n",
    "    if isinstance(locals()[var_name], pd.DataFrame) and not var_name.startswith('_'):\n",
    "        print(var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to CSV\n",
    "To save the contents of a pandas DataFrame to an CSV\n",
    "use the following syntax\n",
    "```\n",
    "host_logons.to_csv('host_logons.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [
     "todo"
    ]
   },
   "source": [
    "## Saving Data to Excel\n",
    "To save the contents of a pandas DataFrame to an Excel spreadsheet\n",
    "use the following syntax\n",
    "```\n",
    "writer = pd.ExcelWriter('myWorksheet.xlsx')\n",
    "my_data_frame.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "318.996px",
    "width": "320.994px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "406.193px",
    "left": "1468.4px",
    "right": "20px",
    "top": "120px",
    "width": "456.572px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
